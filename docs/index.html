

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>DataComPy &mdash; datacompy 0.5.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="datacompy 0.5.0 documentation" href="#"/>
        <link rel="next" title="Installation" href="install.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="#" class="icon icon-home"> datacompy
          

          
          </a>

          
            
            
              <div class="version">
                0.5.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="pandas_usage.html">Pandas Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="spark_usage.html">Spark Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="developer_instructions.html">Developer Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">Module Reference</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">datacompy</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#">Docs</a> &raquo;</li>
        
      <li>DataComPy</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <a class="reference external image-reference" href="https://travis-ci.org/capitalone/datacompy"><img alt="https://travis-ci.org/capitalone/datacompy.svg?branch=master" src="https://travis-ci.org/capitalone/datacompy.svg?branch=master" /></a>
<div class="section" id="datacompy">
<h1>DataComPy<a class="headerlink" href="#datacompy" title="Permalink to this headline">¶</a></h1>
<p>DataComPy is a package to compare two Pandas DataFrames. Originally started to
be something of a replacement for SAS’s <code class="docutils literal"><span class="pre">PROC</span> <span class="pre">COMPARE</span></code> for Pandas DataFrames
with some more functionality than just <code class="docutils literal"><span class="pre">Pandas.DataFrame.equals(Pandas.DataFrame)</span></code>
(in that it prints out some stats, and lets you tweak how accurate matches have to be).
Then extended to carry that functionality over to Spark Dataframes.</p>
<div class="section" id="quick-installation">
<h2>Quick Installation<a class="headerlink" href="#quick-installation" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">datacompy</span>
</pre></div>
</div>
</div>
<div class="section" id="pandas-detail">
<h2>Pandas Detail<a class="headerlink" href="#pandas-detail" title="Permalink to this headline">¶</a></h2>
<p>DataComPy will try to join two dataframes either on a list of join columns, or
on indexes.  If the two dataframes have duplicates based on join values, the
match process sorts by the remaining fields and joins based on that row number.</p>
<p>Column-wise comparisons attempt to match values even when dtypes don’t match.
So if, for example, you have a column with <code class="docutils literal"><span class="pre">decimal.Decimal</span></code> values in one
dataframe and an identically-named column with <code class="docutils literal"><span class="pre">float64</span></code> dtype in another,
it will tell you that the dtypes are different but will still try to compare the
values.</p>
<div class="section" id="basic-usage">
<h3>Basic Usage<a class="headerlink" href="#basic-usage" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">StringIO</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">datacompy</span>

<span class="n">data1</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;acct_id,dollar_amt,name,float_fld,date_fld</span>
<span class="s2">10000001234,123.45,George Maharis,14530.1555,2017-01-01</span>
<span class="s2">10000001235,0.45,Michael Bluth,1,2017-01-01</span>
<span class="s2">10000001236,1345,George Bluth,,2017-01-01</span>
<span class="s2">10000001237,123456,Bob Loblaw,345.12,2017-01-01</span>
<span class="s2">10000001239,1.05,Lucille Bluth,,2017-01-01</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">data2</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;acct_id,dollar_amt,name,float_fld</span>
<span class="s2">10000001234,123.4,George Michael Bluth,14530.155</span>
<span class="s2">10000001235,0.45,Michael Bluth,</span>
<span class="s2">10000001236,1345,George Bluth,1</span>
<span class="s2">10000001237,123456,Robert Loblaw,345.12</span>
<span class="s2">10000001238,1.05,Loose Seal Bluth,111</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">StringIO</span><span class="p">(</span><span class="n">data1</span><span class="p">))</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">StringIO</span><span class="p">(</span><span class="n">data2</span><span class="p">))</span>

<span class="n">compare</span> <span class="o">=</span> <span class="n">datacompy</span><span class="o">.</span><span class="n">Compare</span><span class="p">(</span>
    <span class="n">df1</span><span class="p">,</span>
    <span class="n">df2</span><span class="p">,</span>
    <span class="n">join_columns</span><span class="o">=</span><span class="s1">&#39;acct_id&#39;</span><span class="p">,</span>  <span class="c1">#You can also specify a list of columns</span>
    <span class="n">abs_tol</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="c1">#Optional, defaults to 0</span>
    <span class="n">rel_tol</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="c1">#Optional, defaults to 0</span>
    <span class="n">df1_name</span><span class="o">=</span><span class="s1">&#39;Original&#39;</span><span class="p">,</span> <span class="c1">#Optional, defaults to &#39;df1&#39;</span>
    <span class="n">df2_name</span><span class="o">=</span><span class="s1">&#39;New&#39;</span> <span class="c1">#Optional, defaults to &#39;df2&#39;</span>
    <span class="p">)</span>
<span class="n">compare</span><span class="o">.</span><span class="n">matches</span><span class="p">(</span><span class="n">ignore_extra_columns</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="c1"># False</span>

<span class="c1"># This method prints out a human-readable report summarizing and sampling differences</span>
<span class="k">print</span><span class="p">(</span><span class="n">compare</span><span class="o">.</span><span class="n">report</span><span class="p">())</span>
</pre></div>
</div>
<p>See docs for more detailed usage instructions and an example of the report output.</p>
</div>
<div class="section" id="things-that-are-happening-behind-the-scenes">
<h3>Things that are happening behind the scenes<a class="headerlink" href="#things-that-are-happening-behind-the-scenes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>You pass in two dataframes (<code class="docutils literal"><span class="pre">df1</span></code>, <code class="docutils literal"><span class="pre">df2</span></code>) to <code class="docutils literal"><span class="pre">datacompy.Compare</span></code> and a
column to join on (or list of columns) to <code class="docutils literal"><span class="pre">join_columns</span></code>.  By default the
comparison needs to match values exactly, but you can pass in <code class="docutils literal"><span class="pre">abs_tol</span></code>
and/or <code class="docutils literal"><span class="pre">rel_tol</span></code> to apply absolute and/or relative tolerances for numeric columns.<ul>
<li>You can pass in <code class="docutils literal"><span class="pre">on_index=True</span></code> instead of <code class="docutils literal"><span class="pre">join_columns</span></code> to join on
the index instead.</li>
</ul>
</li>
<li>The class validates that you passed dataframes, that they contain all of the
columns in <cite>join_columns</cite> and have unique column names other than that.  The
class also lowercases all column names to disambiguate.</li>
<li>On initialization the class validates inputs, and runs the comparison.</li>
<li><code class="docutils literal"><span class="pre">Compare.matches()</span></code> will return <code class="docutils literal"><span class="pre">True</span></code> if the dataframes match, <code class="docutils literal"><span class="pre">False</span></code>
otherwise.<ul>
<li>You can pass in <code class="docutils literal"><span class="pre">ignore_extra_columns=True</span></code> to not return <code class="docutils literal"><span class="pre">False</span></code> just
because there are non-overlapping column names (will still check on
overlapping columns)</li>
<li>NOTE: if you only want to validate whether a dataframe matches exactly or
not, you should look at <code class="docutils literal"><span class="pre">pandas.testing.assert_frame_equal</span></code>.  The main
use case for <code class="docutils literal"><span class="pre">datacompy</span></code> is when you need to interpret the difference
between two dataframes.</li>
</ul>
</li>
<li>Compare also has some shortcuts like<ul>
<li><code class="docutils literal"><span class="pre">intersect_rows</span></code>, <code class="docutils literal"><span class="pre">df1_unq_rows</span></code>, <code class="docutils literal"><span class="pre">df2_unq_rows</span></code> for getting
intersection, just df1 and just df2 records (DataFrames)</li>
<li><code class="docutils literal"><span class="pre">intersect_columns()</span></code>, <code class="docutils literal"><span class="pre">df1_unq_columns()</span></code>, <code class="docutils literal"><span class="pre">df2_unq_columns()</span></code> for
getting intersection, just df1 and just df2 columns (Sets)</li>
</ul>
</li>
<li>You can turn on logging to see more detailed logs.</li>
</ul>
</div>
</div>
<div class="section" id="spark-detail">
<span id="id1"></span><h2>Spark Detail<a class="headerlink" href="#spark-detail" title="Permalink to this headline">¶</a></h2>
<p>DataComPy’s <code class="docutils literal"><span class="pre">SparkCompare</span></code> class will join two dataframes either on a list of join
columns. It has the capability to map column names that may be different in each
dataframe, including in the join columns. You are responsible for creating the
dataframes from any source which Spark can handle and specifying a unique join
key. If there are duplicates in either dataframe by join key, the match process
will remove the duplicates before joining (and tell you how many duplicates were
found).</p>
<p>As with the Pandas-based <code class="docutils literal"><span class="pre">Compare</span></code> class, comparisons will be attempted even
if dtypes don’t match. Any schema differences will be reported in the output
as well as in any mismatch reports, so that you can assess whether or not a
type mismatch is a problem or not.</p>
<p>The main reasons why you would choose to use <code class="docutils literal"><span class="pre">SparkCompare</span></code> over <code class="docutils literal"><span class="pre">Compare</span></code>
are that your data is too large to fit into memory, or you’re comparing data
that works well in a Spark environment, like partitioned Parquet, CSV, or JSON
files, or Cerebro tables.</p>
<div class="section" id="performance-implications">
<h3>Performance Implications<a class="headerlink" href="#performance-implications" title="Permalink to this headline">¶</a></h3>
<p>Spark scales incredibly well, so you can use <code class="docutils literal"><span class="pre">SparkCompare</span></code> to compare
billions of rows of data, provided you spin up a big enough cluster. Still,
joining billions of rows of data is an inherently large task, so there are a
couple of things you may want to take into consideration when getting into the
cliched realm of “big data”:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">SparkCompare</span></code> will compare all columns in common in the dataframes and
report on the rest. If there are columns in the data that you don’t care to
compare, use a <code class="docutils literal"><span class="pre">select</span></code> statement/method on the dataframe(s) to filter
those out. Particularly when reading from wide Parquet files, this can make
a huge difference when the columns you don’t care about don’t have to be
read into memory and included in the joined dataframe.</li>
<li>For large datasets, adding <code class="docutils literal"><span class="pre">cache_intermediates=True</span></code> to the <code class="docutils literal"><span class="pre">SparkCompare</span></code>
call can help optimize performance by caching certain intermediate dataframes
in memory, like the de-duped version of each input dataset, or the joined
dataframe. Otherwise, Spark’s lazy evaluation will recompute those each time
it needs the data in a report or as you access instance attributes. This may
be fine for smaller dataframes, but will be costly for larger ones. You do
need to ensure that you have enough free cache memory before you do this, so
this parameter is set to False by default.</li>
</ul>
</div>
<div class="section" id="id2">
<h3>Basic Usage<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">datacompy</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">Row</span>

<span class="c1"># This example assumes you have a SparkSession named &quot;spark&quot; in your environment, as you</span>
<span class="c1"># do when running `pyspark` from the terminal or in a Databricks notebook (Spark v2.0 and higher)</span>

<span class="n">data1</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">acct_id</span><span class="o">=</span><span class="mi">10000001234</span><span class="p">,</span> <span class="n">dollar_amt</span><span class="o">=</span><span class="mf">123.45</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;George Maharis&#39;</span><span class="p">,</span> <span class="n">float_fld</span><span class="o">=</span><span class="mf">14530.1555</span><span class="p">,</span>
        <span class="n">date_fld</span><span class="o">=</span><span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">acct_id</span><span class="o">=</span><span class="mi">10000001235</span><span class="p">,</span> <span class="n">dollar_amt</span><span class="o">=</span><span class="mf">0.45</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Michael Bluth&#39;</span><span class="p">,</span> <span class="n">float_fld</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">date_fld</span><span class="o">=</span><span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">acct_id</span><span class="o">=</span><span class="mi">10000001236</span><span class="p">,</span> <span class="n">dollar_amt</span><span class="o">=</span><span class="mf">1345.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;George Bluth&#39;</span><span class="p">,</span> <span class="n">float_fld</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
        <span class="n">date_fld</span><span class="o">=</span><span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">acct_id</span><span class="o">=</span><span class="mi">10000001237</span><span class="p">,</span> <span class="n">dollar_amt</span><span class="o">=</span><span class="mf">123456.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Bob Loblaw&#39;</span><span class="p">,</span> <span class="n">float_fld</span><span class="o">=</span><span class="mf">345.12</span><span class="p">,</span>
        <span class="n">date_fld</span><span class="o">=</span><span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">acct_id</span><span class="o">=</span><span class="mi">10000001239</span><span class="p">,</span> <span class="n">dollar_amt</span><span class="o">=</span><span class="mf">1.05</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Lucille Bluth&#39;</span><span class="p">,</span> <span class="n">float_fld</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
        <span class="n">date_fld</span><span class="o">=</span><span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="p">]</span>

<span class="n">data2</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">acct_id</span><span class="o">=</span><span class="mi">10000001234</span><span class="p">,</span> <span class="n">dollar_amt</span><span class="o">=</span><span class="mf">123.4</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;George Michael Bluth&#39;</span><span class="p">,</span> <span class="n">float_fld</span><span class="o">=</span><span class="mf">14530.155</span><span class="p">),</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">acct_id</span><span class="o">=</span><span class="mi">10000001235</span><span class="p">,</span> <span class="n">dollar_amt</span><span class="o">=</span><span class="mf">0.45</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Michael Bluth&#39;</span><span class="p">,</span> <span class="n">float_fld</span><span class="o">=</span><span class="bp">None</span><span class="p">),</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">acct_id</span><span class="o">=</span><span class="mi">10000001236</span><span class="p">,</span> <span class="n">dollar_amt</span><span class="o">=</span><span class="mf">1345.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;George Bluth&#39;</span><span class="p">,</span> <span class="n">float_fld</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">acct_id</span><span class="o">=</span><span class="mi">10000001237</span><span class="p">,</span> <span class="n">dollar_amt</span><span class="o">=</span><span class="mf">123456.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Robert Loblaw&#39;</span><span class="p">,</span> <span class="n">float_fld</span><span class="o">=</span><span class="mf">345.12</span><span class="p">),</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">acct_id</span><span class="o">=</span><span class="mi">10000001238</span><span class="p">,</span> <span class="n">dollar_amt</span><span class="o">=</span><span class="mf">1.05</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Loose Seal Bluth&#39;</span><span class="p">,</span> <span class="n">float_fld</span><span class="o">=</span><span class="mf">111.0</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">base_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data1</span><span class="p">)</span>
<span class="n">compare_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data2</span><span class="p">)</span>

<span class="n">comparison</span> <span class="o">=</span> <span class="n">datacompy</span><span class="o">.</span><span class="n">SparkCompare</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="n">base_df</span><span class="p">,</span> <span class="n">compare_df</span><span class="p">,</span> <span class="n">join_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;acct_id&#39;</span><span class="p">])</span>

<span class="c1"># This prints out a human-readable report summarizing differences</span>
<span class="n">comparison</span><span class="o">.</span><span class="n">report</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="using-sparkcompare-on-emr-or-standalone-spark">
<h3>Using SparkCompare on EMR or standalone Spark<a class="headerlink" href="#using-sparkcompare-on-emr-or-standalone-spark" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li>Set proxy variables</li>
<li>Create a virtual environment, if desired (<code class="docutils literal"><span class="pre">virtualenv</span> <span class="pre">venv;</span> <span class="pre">source</span> <span class="pre">venv/bin/activate</span></code>)</li>
<li>Pip install datacompy and requirements</li>
<li>Ensure your SPARK_HOME environment variable is set (this is probably <code class="docutils literal"><span class="pre">/usr/lib/spark</span></code> but may
differ based on your installation)</li>
<li>Augment your PYTHONPATH environment variable with
<code class="docutils literal"><span class="pre">export</span> <span class="pre">PYTHONPATH=$SPARK_HOME/python/lib/py4j-0.10.4-src.zip:$SPARK_HOME/python:$PYTHONPATH</span></code>
(note that your version of py4j may differ depending on the version of Spark you’re using)</li>
</ol>
</div>
<div class="section" id="using-sparkcompare-on-databricks">
<h3>Using SparkCompare on Databricks<a class="headerlink" href="#using-sparkcompare-on-databricks" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li>Clone this repository locally</li>
<li>Create a datacompy egg by running <code class="docutils literal"><span class="pre">python</span> <span class="pre">setup.py</span> <span class="pre">bdist_egg</span></code> from the repo root directory.</li>
<li>From the Databricks front page, click the “Library” link under the “New” section.</li>
<li><dl class="first docutils">
<dt>On the New library page:</dt>
<dd><ol class="first last loweralpha">
<li>Change source to “Upload Python Egg or PyPi”</li>
<li>Under “Upload Egg”, Library Name should be “datacompy”</li>
<li>Drag the egg file in datacompy/dist/ to the “Drop library egg here to upload” box</li>
<li>Click the “Create Library” button</li>
</ol>
</dd>
</dl>
</li>
<li>Once the library has been created, from the library page (which you can find in your /Users/{login} workspace),
you can choose clusters to attach the library to.</li>
<li><code class="docutils literal"><span class="pre">import</span> <span class="pre">datacompy</span></code> in a notebook attached to the cluster that the library is attached to and enjoy!</li>
</ol>
</div>
<div class="section" id="contributors">
<h3>Contributors<a class="headerlink" href="#contributors" title="Permalink to this headline">¶</a></h3>
<p>We welcome your interest in Capital One’s Open Source Projects (the “Project”).
Any Contributor to the project must accept and sign a CLA indicating agreement to
the license terms. Except for the license granted in this CLA to Capital One and
to recipients of software distributed by Capital One, you reserve all right, title,
and interest in and to your contributions; this CLA does not impact your rights to
use your own contributions for any other purpose.</p>
<ul class="simple">
<li><a class="reference external" href="https://docs.google.com/forms/d/19LpBBjykHPox18vrZvBbZUcK6gQTj7qv1O5hCduAZFU/viewform">Link to Individual CLA</a></li>
<li><a class="reference external" href="https://docs.google.com/forms/d/e/1FAIpQLSeAbobIPLCVZD_ccgtMWBDAcN68oqbAJBQyDTSAQ1AkYuCp_g/viewform">Link to Corporate CLA</a></li>
</ul>
<p>This project adheres to the <a class="reference external" href="https://developer.capitalone.com/single/code-of-conduct/">Open Source Code of Conduct</a>.
By participating, you are expected to honor this code.</p>
</div>
</div>
<div class="section" id="contents">
<h2>Contents<a class="headerlink" href="#contents" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="install.html#conda-installs-dependencies-from-conda">conda (installs dependencies from Conda)</a></li>
<li class="toctree-l2"><a class="reference internal" href="install.html#virtualenv-install-dependencies-from-pypi">virtualenv (install dependencies from PyPI)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pandas_usage.html">Pandas Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="pandas_usage.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="pandas_usage.html#compare-object-setup">Compare Object Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="pandas_usage.html#reports">Reports</a></li>
<li class="toctree-l2"><a class="reference internal" href="pandas_usage.html#convenience-methods">Convenience Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="pandas_usage.html#limitations">Limitations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="spark_usage.html">Spark Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="spark_usage.html#known-differences">Known Differences</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="developer_instructions.html">Developer Instructions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="developer_instructions.html#generating-documentation">Generating Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer_instructions.html#run-unit-tests">Run unit tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer_instructions.html#management-of-requirements">Management of Requirements</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">Module Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api/core.html">datacompy.core</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/sparkcompare.html">datacompy.SparkCompare</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="indices-and-tables">
<h2>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></li>
<li><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></li>
<li><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></li>
</ul>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="install.html" class="btn btn-neutral float-right" title="Installation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Capital One.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.5.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>